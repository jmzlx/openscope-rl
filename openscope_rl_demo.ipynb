{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenScope RL: Educational Demo\n",
    "\n",
    "**Training AI to Control Air Traffic**\n",
    "\n",
    "This notebook is **completely self-contained** - all code is defined inline (no project imports).\n",
    "\n",
    "## What You'll See\n",
    "\n",
    "1. **Section 1**: Environment setup (config and OpenScope Gym environment)\n",
    "2. **Section 2**: Component demo (interact with the game)\n",
    "3. **Section 3**: Training with PPO (Stable-Baselines3)\n",
    "4. **Section 4**: Summary and next steps\n",
    "\n",
    "**Key Features**:\n",
    "- ‚úÖ **Simple & Educational** - Focus on RL workflow, not implementation complexity\n",
    "- ‚úÖ **Playwright** browser automation for real game interaction\n",
    "- ‚úÖ **Stable-Baselines3** for easy PPO training\n",
    "- ‚úÖ **Dict observation/action spaces** for structured control\n",
    "\n",
    "**Requirements**: Gymnasium, Stable-Baselines3, Playwright, PyYAML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Section 1: Code Definitions\n",
    "\n",
    "All classes defined inline below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Imports and Configuration\n",
    "\n",
    "Simple setup: Gymnasium for RL, Stable-Baselines3 for PPO, Playwright for browser automation, and YAML for configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è  Set DISPLAY=:99 for virtual display (xvfb)\n",
      "   Make sure xvfb is running: Xvfb :99 -screen 0 1024x768x24 &\n",
      "‚úÖ Directory OK\n",
      "‚úÖ Game server running\n",
      "‚úÖ Config loaded: KLAS\n"
     ]
    }
   ],
   "source": [
    "# Core imports only\n",
    "import time\n",
    "import warnings\n",
    "from typing import Any, Optional\n",
    "import os\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import requests\n",
    "import yaml\n",
    "from gymnasium import spaces\n",
    "\n",
    "# Stable-Baselines3\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up virtual display for WSL/headless environments\n",
    "# This is needed when running notebooks remotely (e.g., through Cursor)\n",
    "if os.environ.get('DISPLAY') is None:\n",
    "    os.environ['DISPLAY'] = ':99'\n",
    "    print(\"üñ•Ô∏è  Set DISPLAY=:99 for virtual display (xvfb)\")\n",
    "    print(\"   Make sure xvfb is running: Xvfb :99 -screen 0 1024x768x24 &\")\n",
    "\n",
    "# Check environment\n",
    "if not os.path.exists('config'):\n",
    "    raise RuntimeError(\"Run from rl_training directory!\")\n",
    "print(\"‚úÖ Directory OK\")\n",
    "\n",
    "# Check game server\n",
    "try:\n",
    "    requests.get('http://localhost:3003', timeout=2)\n",
    "    print(\"‚úÖ Game server running\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è  Start game server: cd ../openscope && npm start\")\n",
    "\n",
    "# Load config as simple dict\n",
    "with open('config/training_config.yaml') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "print(f\"‚úÖ Config loaded: {config['env']['airport']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 OpenScope Environment\n",
    "\n",
    "Import the Gymnasium environment (uses threaded Playwright for Jupyter compatibility):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenScopeEnv imported from environment module\n",
      "   (Playwright runs in a dedicated thread for Jupyter compatibility)\n"
     ]
    }
   ],
   "source": [
    "# Import OpenScopeEnv from the environment module\n",
    "# Note: Uses a dedicated thread for Playwright to avoid Jupyter asyncio conflicts\n",
    "from environment.openscope_env import OpenScopeEnv\n",
    "\n",
    "print('‚úÖ OpenScopeEnv imported from environment module')\n",
    "print('   (Playwright runs in a dedicated thread for Jupyter compatibility)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Component Demo\n",
    "\n",
    "Let's interact with the OpenScope environment to see how it works:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Browser init: headless=False, DISPLAY=:99\n",
      "‚úÖ Using DISPLAY=:99, headless=False\n",
      "‚úÖ Page loaded\n",
      "‚è≥ Waiting 10 seconds for airport to load...\n",
      "‚úÖ Airport load wait complete\n",
      "  Step 1: Time=0.0s, Aircraft=22\n",
      "  Step 2: Time=0.0s, Aircraft=22\n",
      "  Step 3: Time=0.0s, Aircraft=22\n",
      "  Step 4: Time=0.0s, Aircraft=22\n",
      "  Step 5: Time=0.0s, Aircraft=22\n"
     ]
    }
   ],
   "source": [
    "# Create fresh environment (will now have the diagnostic code)\n",
    "env = OpenScopeEnv(\n",
    "    game_url=config['env']['game_url'],\n",
    "    airport=config['env']['airport'],\n",
    "    timewarp=config['env']['timewarp'],\n",
    "    max_aircraft=config['env']['max_aircraft'],\n",
    "    episode_length=config['env']['episode_length'],\n",
    "    action_interval=config['env']['action_interval'],\n",
    "    headless=config['env']['headless'],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "obs, info = env.reset()\n",
    "\n",
    "# Try steps\n",
    "for i in range(5):\n",
    "    action = {'aircraft_id': 20, 'command_type': 0, 'heading': 0, 'altitude': 0, 'speed': 0}\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    print(f\"  Step {i+1}: Time={info['raw_state']['time']:.1f}s, Aircraft={info['aircraft_count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 1: Time=10.0s, Aircraft=23\n",
      "  Step 2: Time=20.0s, Aircraft=23\n",
      "  Step 3: Time=30.0s, Aircraft=23\n",
      "  Step 4: Time=40.0s, Aircraft=23\n",
      "  Step 5: Time=50.0s, Aircraft=23\n"
     ]
    }
   ],
   "source": [
    "env = OpenScopeEnv(\n",
    "    game_url=config['env']['game_url'],\n",
    "    airport=config['env']['airport'],\n",
    "    timewarp=config['env']['timewarp'],\n",
    "    max_aircraft=config['env']['max_aircraft'],\n",
    "    episode_length=config['env']['episode_length'],\n",
    "    action_interval=config['env']['action_interval'],\n",
    "    headless=config['env']['headless'],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "obs, info = env.reset()\n",
    "\n",
    "for i in range(5):\n",
    "    action = {'aircraft_id': 20, 'command_type': 0, 'heading': 0, 'altitude': 0, 'speed': 0}\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "    print(f\"  Step {i+1}: Time={info['raw_state']['time']:.1f}s, Aircraft={info['aircraft_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚ö†Ô∏è CRITICAL: WSL Display Issue**\n",
    "\n",
    "**If you get `TargetClosedError` about \"no XServer running\":**\n",
    "\n",
    "You're on WSL without a display server. OpenScope needs `headless: false` for the game loop to work, but WSL has no display.\n",
    "\n",
    "**Quick Fix (Recommended):**\n",
    "```bash\n",
    "# Install xvfb (virtual display)\n",
    "sudo apt-get update && sudo apt-get install -y xvfb\n",
    "\n",
    "# Restart Jupyter with xvfb\n",
    "cd ~/Projects/atc-ai/rl_training\n",
    "xvfb-run -a jupyter lab\n",
    "```\n",
    "\n",
    "**Alternative:** See `WSL_DISPLAY_FIX.md` for X11 forwarding setup to actually see the browser.\n",
    "\n",
    "**Why we need headless=false:**\n",
    "- In `headless: true` mode, the browser's `requestAnimationFrame` doesn't work properly\n",
    "- Game time stays stuck at 0.0s\n",
    "- Aircraft spawn but simulation doesn't progress\n",
    "- **Solution:** Run headed mode with xvfb (virtual display)\n",
    "\n",
    "**Performance Optimizations:**\n",
    "- `timewarp: 15` (was 5) ‚Üí 3x faster\n",
    "- `action_interval: 10` (was 5) ‚Üí 2x fewer steps  \n",
    "- `episode_length: 1800` (was 3600) ‚Üí 2x faster episodes\n",
    "- **Combined: ~12x faster training** üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Extract Game State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state after reset:\n",
      "  Time: 0.0s\n",
      "  Score: 0\n",
      "  Aircraft: 23\n",
      "\n",
      "‚ö†Ô∏è  WARNING: Time is 0 but aircraft exist!\n",
      "   This means headless mode is preventing the game loop from running\n",
      "   Solution: Set headless: false in config/training_config.yaml\n",
      "   The browser window will be visible but it's necessary for the game to work\n"
     ]
    }
   ],
   "source": [
    "obs, info = env.reset()\n",
    "\n",
    "# Check initial state\n",
    "state = env._get_game_state()\n",
    "print(f\"Initial state after reset:\")\n",
    "print(f\"  Time: {state.get('time', 0):.1f}s\")\n",
    "print(f\"  Score: {state.get('score', 0)}\")\n",
    "print(f\"  Aircraft: {len(state.get('aircraft', []))}\")\n",
    "\n",
    "# IMPORTANT: If time is stuck at 0.0s, set headless=False in config!\n",
    "# The game's animation loop (requestAnimationFrame) doesn't run properly in headless mode\n",
    "\n",
    "if state.get('time', 0) == 0 and len(state.get('aircraft', [])) > 0:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: Time is 0 but aircraft exist!\")\n",
    "    print(\"   This means headless mode is preventing the game loop from running\")\n",
    "    print(\"   Solution: Set headless: false in config/training_config.yaml\")\n",
    "    print(\"   The browser window will be visible but it's necessary for the game to work\")\n",
    "else:\n",
    "    # Increase timewarp for faster testing\n",
    "    print(f\"\\nSetting timewarp to 15 for faster testing...\")\n",
    "    env._execute_command(\"timewarp 15\")\n",
    "    time.sleep(1.0)\n",
    "    \n",
    "    # Step through to advance game time and spawn aircraft\n",
    "    print(\"\\nAdvancing game time to spawn aircraft...\")\n",
    "    print(\"(Each step = 10 game seconds with action_interval=10)\")\n",
    "    \n",
    "    prev_time = state.get('time', 0)\n",
    "    for i in range(90):  # 90 steps √ó 10 sec = 900 seconds = 15 minutes game time\n",
    "        action = {\n",
    "            'aircraft_id': 20,  # No action\n",
    "            'command_type': 0,\n",
    "            'heading': 0,\n",
    "            'altitude': 0,\n",
    "            'speed': 0\n",
    "        }\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        \n",
    "        # Print progress every 18 steps (3 min of game time)\n",
    "        if (i + 1) % 18 == 0:\n",
    "            current_time = info['raw_state']['time']\n",
    "            time_delta = current_time - prev_time\n",
    "            print(f\"  Step {i+1:3d}: Time={current_time:6.1f}s (+{time_delta:5.1f}s), Aircraft={info['aircraft_count']}\")\n",
    "            prev_time = current_time\n",
    "    \n",
    "    state = env._get_game_state()\n",
    "    print(f\"\\nFinal State:\")\n",
    "    print(f\"  Time: {state.get('time', 0):.1f}s\")\n",
    "    print(f\"  Score: {state.get('score', 0)}\")\n",
    "    print(f\"  Aircraft: {len(state.get('aircraft', []))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Visualize Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active aircraft: 20/20\n",
      "Global state: [0.   1.25 0.   0.  ]\n",
      "Conflicts: 0\n"
     ]
    }
   ],
   "source": [
    "obs = env._state_to_observation(state)\n",
    "aircraft_mask = obs['aircraft_mask']\n",
    "num_active = aircraft_mask.sum()\n",
    "\n",
    "print(f\"Active aircraft: {num_active}/{env.max_aircraft}\")\n",
    "print(f\"Global state: {obs['global_state']}\")\n",
    "print(f\"Conflicts: {(obs['conflict_matrix'] > 0).sum() // 2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Training with PPO\n",
    "\n",
    "Simple PPO training using Stable-Baselines3:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Create PPO Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize environment for SB3\n",
    "vec_env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# Create PPO model with built-in MultiInputPolicy\n",
    "model = PPO(\n",
    "    \"MultiInputPolicy\",  # SB3's built-in policy for Dict spaces\n",
    "    vec_env,\n",
    "    learning_rate=config['ppo']['learning_rate'],\n",
    "    gamma=config['ppo']['gamma'],\n",
    "    gae_lambda=config['ppo']['gae_lambda'],\n",
    "    clip_range=config['ppo']['clip_epsilon'],\n",
    "    n_steps=config['ppo']['n_steps'],\n",
    "    batch_size=config['ppo']['batch_size'],\n",
    "    n_epochs=config['ppo']['n_epochs'],\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "print('‚úÖ PPO model created')\n",
    "print(f'   Learning rate: {config[\"ppo\"][\"learning_rate\"]}')\n",
    "print(f'   Gamma: {config[\"ppo\"][\"gamma\"]}')\n",
    "print(f'   Steps per update: {config[\"ppo\"][\"n_steps\"]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model (uncomment to run)\n",
    "# model.learn(total_timesteps=10_000, progress_bar=True)\n",
    "# model.save(\"checkpoints/openscope_ppo\")\n",
    "\n",
    "print(\"‚è≠Ô∏è  Training skipped (uncomment to run)\")\n",
    "print(\"   For real training, use 100k+ timesteps\")\n",
    "print(\"   Current config: 10k timesteps for quick demo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Summary\n",
    "\n",
    "## What We Built\n",
    "\n",
    "‚úÖ **OpenScope Environment** - Playwright browser automation for real ATC simulation  \n",
    "‚úÖ **Gymnasium interface** - Standard RL environment with Dict obs/action spaces  \n",
    "‚úÖ **PPO Training** - Simple Stable-Baselines3 setup ready to train  \n",
    "‚úÖ **Self-contained** - All code in one notebook for easy learning\n",
    "\n",
    "## Key Simplifications\n",
    "\n",
    "This notebook focuses on **RL workflow over implementation details**:\n",
    "\n",
    "- **Simple config**: Direct YAML dict loading (no Pydantic overhead)\n",
    "- **Built-in policy**: SB3's MultiInputPolicy handles Dict spaces automatically  \n",
    "- **No custom networks**: Focus on environment interaction, not architecture\n",
    "- **Clear structure**: 4 sections from setup to training\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "**To actually train**:\n",
    "1. Uncomment training code in Section 3.2\n",
    "2. Increase timesteps to 100k+ for meaningful results\n",
    "3. Monitor with TensorBoard: `tensorboard --logdir logs`\n",
    "\n",
    "**To improve performance**:\n",
    "- Add custom Transformer network for variable aircraft (see original version)\n",
    "- Implement curriculum learning (start with fewer aircraft)\n",
    "- Try reward shaping (add conflict penalties, progress bonuses)\n",
    "- Use parallel environments for faster training\n",
    "\n",
    "**To extend**:\n",
    "- Test on multiple airports (KJFK, EGLL, KSEA)\n",
    "- Add evaluation metrics (conflicts, efficiency, score)\n",
    "- Implement hierarchical policies (conditional actions)\n",
    "- Export trained model for deployment\n",
    "\n",
    "**Resources**: See `CLAUDE.md` for full project documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "env.close()\n",
    "print('‚úÖ Environment closed!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
