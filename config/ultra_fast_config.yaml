# ULTRA FAST Configuration - Maximum speed (may be unstable!)
# Use this to iterate quickly, but expect some browser crashes

env:
  airport: "KLAS"
  timewarp: 20  # AGGRESSIVE: 20x speed (was 30, reduced for stability)
  max_aircraft: 3  # MINIMAL: fewer aircraft = faster
  episode_length: 600  # SHORT: 10 minutes game time (was 300, increased so episodes complete)
  action_interval: 2  # AGGRESSIVE: 2 seconds between actions
  game_url: "http://localhost:3003"
  headless: true

ppo:
  learning_rate: 3.0e-4
  gamma: 0.99
  gae_lambda: 0.95
  clip_epsilon: 0.2
  value_coef: 0.5
  entropy_coef: 0.01
  max_grad_norm: 0.5
  n_steps: 64  # TINY: update every 64 steps for rapid feedback
  n_epochs: 3  # REDUCED: fewer epochs per update
  batch_size: 16  # SMALL: faster gradient steps
  n_envs: 8

network:
  aircraft_feature_dim: 32
  global_feature_dim: 16
  hidden_dim: 256
  num_attention_heads: 8
  num_transformer_layers: 4
  max_aircraft_slots: 20

actions:
  altitudes: [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180]
  heading_changes: [-90, -60, -45, -30, -20, -10, 0, 10, 20, 30, 45, 60, 90]
  speeds: [180, 200, 220, 240, 260, 280, 300, 320]
  special_actions: ["ils_approach", "direct_to_exit", "hold", "no_action"]

rewards:
  successful_landing: 10
  successful_departure: 10
  collision: -1000
  separation_loss: -200
  airspace_bust: -200
  route_violation: -25
  go_around: -50
  timestep_penalty: -0.01
  progress_reward: 0.5
  conflict_warning: -2.0
  safe_separation_bonus: 0.05
  workload_penalty: -0.1

curriculum:
  enabled: false

training:
  total_timesteps: 50000  # Quick test run
  save_interval: 2500
  eval_interval: 1000
  eval_episodes: 2
  checkpoint_dir: "checkpoints"
  log_dir: "logs"
  use_wandb: false
  wandb_project: "openscope-rl"
  seed: 42

