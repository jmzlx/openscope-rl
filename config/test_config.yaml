# Fast Testing Configuration - Quick feedback for debugging

env:
  airport: "KLAS"
  timewarp: 10  # INCREASED: 10x speed
  max_aircraft: 5  # REDUCED: fewer aircraft
  episode_length: 600  # REDUCED: 10 minutes instead of 1 hour
  action_interval: 3  # REDUCED: faster actions
  game_url: "http://localhost:3003"
  headless: true

ppo:
  learning_rate: 3.0e-4
  gamma: 0.99
  gae_lambda: 0.95
  clip_epsilon: 0.2
  value_coef: 0.5
  entropy_coef: 0.01
  max_grad_norm: 0.5
  n_steps: 128  # REDUCED: much faster updates! (was 2048)
  n_epochs: 4    # REDUCED: faster training cycles
  batch_size: 32

network:
  aircraft_feature_dim: 14
  global_feature_dim: 4
  hidden_dim: 256
  num_attention_heads: 8
  num_transformer_layers: 4
  max_aircraft_slots: 20

actions:
  altitudes: [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180]
  heading_changes: [-90, -60, -45, -30, -20, -10, 0, 10, 20, 30, 45, 60, 90]
  speeds: [180, 200, 220, 240, 260, 280, 300, 320]

rewards:
  successful_landing: 10
  successful_departure: 10
  collision: -1000
  separation_loss: -200
  airspace_bust: -200
  route_violation: -25
  go_around: -50
  timestep_penalty: -0.01
  progress_reward: 0.5
  conflict_warning: -2.0
  safe_separation_bonus: 0.05
  workload_penalty: -0.1

curriculum:
  enabled: false  # DISABLED for testing

training:
  total_timesteps: 100000  # REDUCED for quick test
  save_interval: 5000
  eval_interval: 2500
  eval_episodes: 3
  checkpoint_dir: "checkpoints"
  log_dir: "logs"
  use_wandb: false  # DISABLED for testing
  wandb_project: "openscope-rl"
  seed: 42

